# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

---

Название | Описание
--- | ---
Краткое описание инцидента | 21.10.2018 в 22:52 Пострадали несколько сервисов на GitHub.com. Была нарушена работа сетевых разделов, что привело к нарушению работы базы данных. Все эти нарушения в работе привели к ухудшению качества обслуживания на 24 часа 11 минут.
Предшествующие события | 21 октября в 22:52 Проводилось ТО по замене вышедшего из строя оптического оборудования 100G между Хабом US East Coast network и Основным US East Coast data center
Причина инцидента | Потеря связи между сетевым концентратором на US East Coast network и Основным US East Coast data center - на 43 секунды, что привело к рассинхронизации кластеров MySQL.
Воздействие | GitHub не мог обслуживать события веб-перехватчиков или создавать и публиковать GitHub Pages
Обнаружение | 21 октября 22:54 системы мониторинга начали генерировать предупреждения. В 23:02 инженеры группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии
Реакция | Связь между точками была восстановлена за 43 секунды, но этот кратковременный сбой вызвал цепочку событий, которые привели к ухудшению качества обслуживания на 24 часа 11 минут
Восстановление | Были проведены работы по восстановлению сервисов из резервных копий MySQL и синхронизации реплик на обоих сайтах, возобновлена обработка заданий в очереди
Таймлайн | `21 октября 22:52` Аварийное переключение кластеров для направления операций записи в ЦОД на западном побережье США </br> `21 октября 22:54` Системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах </br> `21 октября 23:07` Отвечающая команда решила вручную заблокировать внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений </br> `21 октября 23:13` Были вызваны дополнительные инженеры из группы разработки баз данных GitHub </br> `21 октября 23:19` Приостановка доставки веб-перехватчика и сборки страниц GitHub </br> `22 октября 00:05` Разработка плана по устранению несоответствий данных и внедрения процедур аварийного переключения для MySQL </br> `22 октября 00:41` Был инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры следили за его ходом </br> `22 октября 06:51` Несколько кластеров завершили восстановление из резервных копий в ЦОД и начали репликацию новых данных с западного побережья </br> `22 октября 07:46` GitHub опубликовал сообщение в блоге, чтобы предоставить больше информации </br> `22 октября 11:12` Все первичные базы данных снова установлены на восточном побережье США </br> `22 октября 13:15` Начали предоставлять дополнительные реплики чтения MySQL в общедоступном облаке восточного побережья США </br> `22 октября 16:24` Выполнено аварийное переключение на исходную топологию, решив проблемы с задержкой/доступностью </br> `22 октября 16:45` Включили обработку данных, мы обработали около 200 000 полезных нагрузок веб-перехватчиков, которые пережили внутренний TTL и были удалены. Обнаружив это, приостановили обработку и внесли изменение, чтобы на время увеличить этот TTL </br> `22 октября 23:03` Все задачи ожидающие сборки вебхуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем
Последующие действия | Был выявлен ряд технических инициатив: </br> -  Оптимизация работы Оркестратора для снижения рисков, которые могут привести к подобному случаю </br> - Изменение модели оповещения о статусе (более подробная информация о работе) </br> - Запланировано мероприятие по изменению работы цодов, главной целью которого является возможность сохранения работоспособности все системы после потери одного из цодов.